{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90bbb081-3998-460c-a9d6-707be65be948",
   "metadata": {},
   "source": [
    "# `pandantic` v1- Solving the issue of black box `DataFrames` with `pydantic`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61059d4c-9964-4bc3-9518-19e97cb7f07f",
   "metadata": {},
   "source": [
    "# Background"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2f6896-b960-410d-9857-bf31a41ef21d",
   "metadata": {},
   "source": [
    "In recent years I grown to favor a \"walled garden\" approach to writing Python applications. The concept is simple: instead of type-checking values with conditional if/else logic across my program, focus only on strict validation of data entry points, allowing the rest of the code to operate safely without tedium. \n",
    "The in-depth validation control `pydantic` offers has made this approach more powerful than ever before…that is, if you are working with JSON or dBase data that gets stored in-memory as a `dict`. However, in the Python data world `DataFrame` objects have become the nearly ubiquitous in-memory representation of data for a variety of convenience and efficiency reasons. This created a conflict between the pydantic model focused code I would write, and the black-box-esque `DataFrame` objects I would also have to utilize.\n",
    "\n",
    "\n",
    "While this is the status quo for most, I began resenting it for a few reasons:\n",
    "You have no way of knowing by looking at code whether a column exists in a `DataFrame` without statements like `assert hasattr(df, \"my_column\")`. This makes reasoning in an unfamiliar repo slower.\n",
    "\n",
    "\n",
    "Some anomaly in the data would cause pandas to infer a data type incorrectly (i.e., object instead of int64 ), which goes uncaught but causes bugs downstream.\n",
    "There are invalid values that cannot be identified by data type alone. For example, you could have a float column that represents values along a sin wave from -1 to 1. While the data type may be correct, you would need to use `df.loc[(df.my_column >= -1) & (df.my_column <= 1)]` to sub-select only valid rows.\n",
    "\n",
    "\n",
    "These issues at a small scale are easy enough to remedy. However, when custom logic became needed for many columns, I would feel forced to choose between safe/verbose vs risky/simple. I found myself wishing there was an easy way to re-use my `pydantic` models for my `pandas` code…enter `pandantic`, which allows you to do exactly that!\n",
    "After some experimenting, I concluded that some additional features and refinement would make me ready to use pandantic in much of my production code. The repo's maintainer Wessel Huising got in contacted and teamed up to make these improvements and publish a proper Pandantic V1 release which is available today on PyPi.\n",
    "Not quite convinced? Well let's walk through a couple illustrative examples. Note that both examples are apart of a notebook here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d31acb-d1ad-4a7d-9243-010b7c622fc0",
   "metadata": {},
   "source": [
    "## Setup for examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a88f2be-c6ad-4637-8e39-f6ddd5af9008",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydantic\n",
    "import pandantic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb63ce0-68bf-4e12-8cf8-da7933926a01",
   "metadata": {},
   "source": [
    "## Example 1: filter invalid rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600db79a-0cde-4bd5-8f30-f01e8e1da5c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "acf3492d-5eaf-4171-92ad-87e129d2fff2",
   "metadata": {},
   "source": [
    "## Example 2: validate upon iteration with the `pandas` plugin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1eae79-6f43-418b-aa8b-f5012529668c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
